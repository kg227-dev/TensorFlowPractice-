{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks Basics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three gates in this unit: Input Gate (handles writing of data into the information cell), Output Gate (handles sending data back onto the Recurrent Network), and Keep Gate (handles maintaining and modifiction of data stored in the information cell). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a network with one LSTM cell. We pass prv_output and prv_state elements to LSTM. State is a tuple with 2 elements, each one of size 1X4. One is passed to prv_output to next time step, and another for prv_state to next time stamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'zeros:0' shape=(1, 4) dtype=float32>,\n",
       " <tf.Tensor 'zeros:0' shape=(1, 4) dtype=float32>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_Cell_Size = 4 #output size dimension\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(LSTM_Cell_Size, state_is_tuple = True)\n",
    "state = (tf.zeros([1,LSTM_Cell_Size]),)*2\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 2. 2. 3. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "sample_input = tf.constant([[3,2,2,3,2,2]], dtype=tf.float32)\n",
    "print(sess.run(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=array([[0.14033972, 0.81582224, 0.82371634, 0.29101387]], dtype=float32), h=array([[0.06975102, 0.6445508 , 0.33219245, 0.03023778]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"LSTM_sample1\"):\n",
    "    output, state_new = lstm_cell(sample_input, state)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(state_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06975102 0.6445508  0.33219245 0.03023778]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state has 2 parts: new state c, and output h. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-Layer LSTM, where the output of the first layer will become the input of the second layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-b4038dc8fce1>:2: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "LSTM_Cell_Size_1 = 4 #4 hidden nodes\n",
    "cell1 = tf.contrib.rnn.LSTMCell(LSTM_Cell_Size_1)\n",
    "cells.append(cell1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Cell_Size2 = 5 #5 hidden nodes\n",
    "cell2 = tf.contrib.rnn.LSTMCell(LSTM_Cell_Size2)\n",
    "cells.append(cell2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-4cb0e5b3e12a>:1: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-aac94950a8f7>:3: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "# Batch size, time steps, features\n",
    "data = tf.placeholder(tf.float32, [None,None, input_dim])\n",
    "output, state = tf.nn.dynamic_rnn(stacked_lstm, data, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input should be a Tensor of shape: [batch_size, max_time, dimension], in our case it would be (2, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3, 4, 3, 2], [1, 2, 1, 1, 1, 2], [1, 2, 2, 2, 2, 2]],\n",
       " [[1, 2, 3, 4, 3, 2], [3, 2, 2, 1, 1, 2], [0, 0, 0, 0, 3, 2]]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batch size x time steps x features.\n",
    "sample_input = [[[1,2,3,4,3,2], [1,2,1,1,1,2],[1,2,2,2,2,2]],[[1,2,3,4,3,2],[3,2,2,1,1,2],[0,0,0,0,3,2]]]\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose_1:0' shape=(?, ?, 5) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.01573942,  0.02947374, -0.04671409, -0.05581208,\n",
       "          0.00198461],\n",
       "        [-0.03288725,  0.05618233, -0.07481771, -0.09141026,\n",
       "          0.01093547],\n",
       "        [-0.05817969,  0.09239119, -0.11113288, -0.11899582,\n",
       "          0.00466868]],\n",
       "\n",
       "       [[-0.01573942,  0.02947374, -0.04671409, -0.05581209,\n",
       "          0.00198461],\n",
       "        [-0.02906859,  0.05948253, -0.07529968, -0.09817882,\n",
       "          0.02598765],\n",
       "        [-0.02588988,  0.04673268, -0.04770134, -0.0830615 ,\n",
       "          0.03575632]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(output, feed_dict ={data: sample_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the output is of shape (2, 3, 5), which corresponds to our 2 batches, 3 elements in our sequence, and the dimensionality of the output which is 5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
